import subprocess
import shlex

class Evaluator:
    """
    This agent evaluates the generated answer for faithfulness to the retrieved documents.
    It uses a local Ollama model via subprocess.
    """
    def __init__(self, model_name: str = "openchat:latest"):
        self.model_name = model_name

    def evaluate(self, query: str, documents: list[str], generated_answer: str) -> bool:
        """
        Evaluates the generated answer for faithfulness.

        Args:
            query: The user's original query.
            documents: The list of retrieved documents.
            generated_answer: The answer generated by the Generator agent.

        Returns:
            True if the answer is faithful to the documents, False otherwise.
        """
        print("Evaluating the generated answer for faithfulness...")

        context = "\n\n".join(documents)

        prompt_template = (
            "You are a strict evaluator. Your task is to determine if the provided 'Answer' is fully supported by the 'Context'. "
            "The answer must not contain any information that is not present in the context. "
            "Respond with only the word 'yes' or 'no'.\n\n"
            "Context:\n"
            "---CONTEXT---\n"
            "{context}\n"
            "---END CONTEXT---\n\n"
            "Answer:\n"
            "---ANSWER---\n"
            "{answer}\n"
            "---END ANSWER---\n\n"
            "Is the answer fully supported by the context? (yes/no):"
        )

        prompt = prompt_template.format(context=context, answer=generated_answer)

        command = ["ollama", "run", self.model_name, prompt]

        try:
            print("---CALLING OLLAMA FOR EVALUATION VIA SUBPROCESS---")
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                encoding="utf-8",
                check=True
            )

            response_text = result.stdout.strip().lower()
            print(f"---OLLAMA RESPONSE---\n{response_text}\n---END OLLAMA RESPONSE---")

            return "yes" in response_text

        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            print(f"Error evaluating answer: {e}. Defaulting to faithful (True).")
            # Default to True to avoid stopping the pipeline due to an evaluation error.
            # In a production system, this might require more sophisticated error handling.
            return True
